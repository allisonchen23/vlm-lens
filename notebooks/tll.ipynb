{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df00cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "sys.path.insert(0, '..')\n",
    "from main import get_model\n",
    "from models.config import Config, IMAGE_TOKEN_IDS\n",
    "import db_utils, utils, visualizations, similarity_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25331ad",
   "metadata": {},
   "source": [
    "## Obtain paths for non-face TLL image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d086e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_images(data_dir,\n",
    "                  visualize=False,\n",
    "                  save_dir=None,\n",
    "                  overwrite=False):\n",
    "    if save_dir is not None:\n",
    "        right_save_path = os.path.join(save_dir, \"filtered_right_paths.txt\")\n",
    "        left_save_path = os.path.join(save_dir, \"filtered_left_paths.txt\")\n",
    "        if os.path.exists(right_save_path) and os.path.exists(left_save_path) and not overwrite:\n",
    "            utils.informal_log(\"File exists at {} and {} and not overwriting\".format(\n",
    "                left_save_path, right_save_path))\n",
    "            return utils.read_file(left_save_path), utils.read_file(left_save_path)\n",
    "\n",
    "    metadata_path = os.path.join(data_dir, \"metadata.pkl\")\n",
    "    metadata = utils.read_file(metadata_path)\n",
    "\n",
    "    # Map image names from Images/ to right/left names\n",
    "    paired_image_names = metadata['image_list']\n",
    "    single_image_names = sorted(os.listdir(os.path.join(data_dir, \"right\")))\n",
    "    paired_single_dict = dict(zip(paired_image_names, single_image_names))\n",
    "\n",
    "    # Get list of image names that are in \"no_faces\"\n",
    "    filtered_boolean = metadata['no_faces']\n",
    "    filtered_paired_image_names = np.array(paired_image_names)[filtered_boolean]\n",
    "    # Get the corresponding right/left image names\n",
    "    filtered_single_image_names = [paired_single_dict[paired_name] for paired_name in filtered_paired_image_names]\n",
    "    assert len(filtered_paired_image_names) == len(filtered_single_image_names)\n",
    "    if visualize:\n",
    "        rand_int = random.randint(0, len(filtered_single_image_names) - 1)\n",
    "        utils.informal_log(\"Randomly visualizing image {}\".format(rand_int))\n",
    "        visualizations.show_image_rows(\n",
    "            [[utils.read_file(os.path.join(data_dir, \"Images\", filtered_paired_image_names[rand_int])),\n",
    "            utils.read_file(os.path.join(data_dir, \"left\", filtered_single_image_names[rand_int])),\n",
    "            utils.read_file(os.path.join(data_dir, \"right\", filtered_single_image_names[rand_int]))]]\n",
    "        )\n",
    "\n",
    "    # Make separate lists for right and left\n",
    "    left_save_paths = []\n",
    "    right_save_paths = []\n",
    "    for filename in filtered_single_image_names:\n",
    "        left_save_paths.append(os.path.join(data_dir, \"left\", filename))\n",
    "        right_save_paths.append(os.path.join(data_dir, \"right\", filename))\n",
    "    if save_dir is not None:\n",
    "        utils.write_file(left_save_paths, left_save_path, overwrite=overwrite)\n",
    "        utils.write_file(right_save_paths, right_save_path, overwrite=overwrite)\n",
    "\n",
    "    return left_save_paths, right_save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e205ed53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1027_094803] File exists at ../data_local/tll/filtered_left_paths.txt and ../data_local/tll/filtered_right_paths.txt and not overwriting\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data_local/tll/totally_looks_like\"\n",
    "save_dir = \"../data_local/tll\"\n",
    "\n",
    "image_names = filter_images(\n",
    "    data_dir=data_dir,\n",
    "    visualize=True,\n",
    "    save_dir=save_dir,\n",
    "    overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7f211",
   "metadata": {},
   "source": [
    "## Run Model on Left and Right Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495374db",
   "metadata": {},
   "source": [
    "### Left Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d165e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['notebooks/get_representations.ipynb',\n",
    "            '--config', '../configs/models/qwen/Qwen2-VL-7B-Instruct-TLL-Left.yaml']\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853d4a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 24.17it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual.blocks.31\n",
      "visual.merger\n",
      "model.layers.27\n",
      "model.norm\n",
      "[1027_162306] 4 modules matched\n"
     ]
    }
   ],
   "source": [
    "model = get_model(config.architecture, config)\n",
    "\n",
    "\n",
    "n_modules = 0\n",
    "layer_names = []\n",
    "for name, module in model.model.named_modules():\n",
    "    if model.config.matches_module(name):\n",
    "        print(name)\n",
    "        layer_names.append(name)\n",
    "        n_modules += 1\n",
    "utils.informal_log(\"{} modules matched\".format(n_modules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34baf31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1027_162309] Database path: ../output/TLL/Qwen2-VL-7B-Instruct/TLL-Left.db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1027_162310] Not overwriting file at ../output/TLL/Qwen2-VL-7B-Instruct/TLL-Left.db\n"
     ]
    }
   ],
   "source": [
    "# Run model -- first checking if we would overwrite anything\n",
    "left_db_path = model.config.output_db\n",
    "utils.informal_log(\"Database path: {}\".format(left_db_path))\n",
    "proceed = True\n",
    "if os.path.exists(left_db_path):\n",
    "    response = input(\"File exists at {}. Are you sure you want to overwrite? (Y/N)\".format(left_db_path))\n",
    "    if response.lower() != \"y\":\n",
    "        proceed = False\n",
    "    else:\n",
    "        os.remove(left_db_path)\n",
    "\n",
    "if proceed:\n",
    "    # Run model on images\n",
    "    model.run(save_tokens=True)\n",
    "else:\n",
    "    utils.informal_log(\"Not overwriting file at {}\".format(left_db_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c921a",
   "metadata": {},
   "source": [
    "### Right Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6805261",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['notebooks/get_representations.ipynb',\n",
    "            '--config', '../configs/models/qwen/Qwen2-VL-7B-Instruct-TLL-Right.yaml']\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25552f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 23.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual.blocks.31\n",
      "visual.merger\n",
      "model.layers.27\n",
      "model.norm\n",
      "[1027_162319] 4 modules matched\n"
     ]
    }
   ],
   "source": [
    "model = get_model(config.architecture, config)\n",
    "\n",
    "\n",
    "n_modules = 0\n",
    "layer_names = []\n",
    "for name, module in model.model.named_modules():\n",
    "    if model.config.matches_module(name):\n",
    "        print(name)\n",
    "        layer_names.append(name)\n",
    "        n_modules += 1\n",
    "utils.informal_log(\"{} modules matched\".format(n_modules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bf38c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1027_162319] Database path: ../output/TLL/Qwen2-VL-7B-Instruct/TLL-Right.db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1027_162321] Not overwriting file at ../output/TLL/Qwen2-VL-7B-Instruct/TLL-Right.db\n"
     ]
    }
   ],
   "source": [
    "# Run model -- first checking if we would overwrite anything\n",
    "right_db_path = model.config.output_db\n",
    "utils.informal_log(\"Database path: {}\".format(right_db_path))\n",
    "proceed = True\n",
    "if os.path.exists(right_db_path):\n",
    "    response = input(\"File exists at {}. Are you sure you want to overwrite? (Y/N)\".format(right_db_path))\n",
    "    if response.lower() != \"y\":\n",
    "        proceed = False\n",
    "    else:\n",
    "        os.remove(right_db_path)\n",
    "\n",
    "if proceed:\n",
    "    # Run model on images\n",
    "    model.run(save_tokens=True)\n",
    "else:\n",
    "    utils.informal_log(\"Not overwriting file at {}\".format(right_db_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc850d2",
   "metadata": {},
   "source": [
    "## TODO: Add instructions to run the python script notebooks/tll.py in order to save from .db -> .npy files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1aa53",
   "metadata": {},
   "source": [
    "## Get Embeddings and Compute Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0b89d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1027_163943] File exists at ../output/TLL/Qwen2-VL-7B-Instruct/similarities/sim-visual.blocks.31.npy and not overwriting\n",
      "(1622, 144, 3584) (1622, 144, 3584)\n",
      "visual.merger 0.780057403762651\n",
      "Saved file to ../output/TLL/Qwen2-VL-7B-Instruct/similarities/sim-visual.merger.npy\n",
      "(1622, 170, 3584) (1622, 170, 3584)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 37\u001b[0m\n\u001b[1;32m     31\u001b[0m right_embedding, right_same_shapes \u001b[38;5;241m=\u001b[39m similarity_utils\u001b[38;5;241m.\u001b[39mget_embedding(\n\u001b[1;32m     32\u001b[0m     database_path\u001b[38;5;241m=\u001b[39mright_db_dir,\n\u001b[1;32m     33\u001b[0m     layer_name\u001b[38;5;241m=\u001b[39mlayer_name\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(left_embedding\u001b[38;5;241m.\u001b[39mshape, right_embedding\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 37\u001b[0m left_modality_name, left_modality_embedding, left_n_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43msimilarity_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_modality\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_modality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_modality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMAGE_TOKEN_IDS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marchitecture\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_embedding_same_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_same_shapes\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m right_modality_name, right_modality_embedding, right_n_embeddings \u001b[38;5;241m=\u001b[39m similarity_utils\u001b[38;5;241m.\u001b[39mextract_modality(\n\u001b[1;32m     48\u001b[0m     layer_modality\u001b[38;5;241m=\u001b[39mlayer_modality,\n\u001b[1;32m     49\u001b[0m     modality\u001b[38;5;241m=\u001b[39mmodality,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39mright_input_ids,\n\u001b[1;32m     54\u001b[0m     module_embedding_same_shapes\u001b[38;5;241m=\u001b[39mright_same_shapes)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Calculate mean embedding\u001b[39;00m\n",
      "File \u001b[0;32m/n/fs/ac-vlm/vlm-lens/notebooks/../src/similarity_utils.py:72\u001b[0m, in \u001b[0;36mextract_modality\u001b[0;34m(layer_modality, modality, module_embedding, module_name, image_token_id, input_ids, module_embedding_same_shapes)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvision\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m     70\u001b[0m         image_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m     71\u001b[0m         module_embedding_same_shapes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     modality_embedding, n_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mdb_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_visual_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43msame_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_embedding_same_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     modality_name \u001b[38;5;241m=\u001b[39m  module_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(modality)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/n/fs/ac-vlm/vlm-lens/notebooks/../src/db_utils.py:370\u001b[0m, in \u001b[0;36mextract_visual_embeddings\u001b[0;34m(input_ids, llm_embeddings, image_token_id, same_shapes)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03mGiven input IDs and LLM embeddings,\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    return tokens that are of the image representation; text tokens become 0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    visual_tokens, n_visual_tokens : B x T x D np.array, B-dim integer np.array\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m same_shapes:\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Check that Batch and Token dimensions match\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m llm_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m llm_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_ids\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "modality = \"vision\"\n",
    "left_db_dir = os.path.splitext(left_db_path)[0]\n",
    "right_db_dir = os.path.splitext(right_db_path)[0]\n",
    "\n",
    "left_input_ids = similarity_utils.get_embedding(\n",
    "    database_path=left_db_dir,\n",
    "    layer_name=\"input_ids\"\n",
    ")\n",
    "\n",
    "right_input_ids = similarity_utils.get_embedding(\n",
    "    database_path=right_db_dir,\n",
    "    layer_name=\"input_ids\"\n",
    ")\n",
    "\n",
    "similarity_save_dir = os.path.join(os.path.dirname(left_db_dir), \"similarities\")\n",
    "utils.ensure_dir(similarity_save_dir)\n",
    "overwrite = False\n",
    "\n",
    "for layer_name in tqdm(layer_names):\n",
    "    save_path = os.path.join(similarity_save_dir, \"sim-{}.npy\".format(layer_name))\n",
    "    if os.path.exists(save_path) and not overwrite:\n",
    "        utils.informal_log(\"File exists at {} and not overwriting\".format(save_path))\n",
    "        continue\n",
    "\n",
    "    layer_modality = model.get_layer_modality(layer_name)\n",
    "    left_embedding, left_same_shapes = similarity_utils.get_embedding(\n",
    "        database_path=left_db_dir,\n",
    "        layer_name=layer_name\n",
    "    )\n",
    "\n",
    "    right_embedding, right_same_shapes = similarity_utils.get_embedding(\n",
    "        database_path=right_db_dir,\n",
    "        layer_name=layer_name\n",
    "    )\n",
    "    print(left_embedding.shape, right_embedding.shape)\n",
    "\n",
    "    left_modality_name, left_modality_embedding, left_n_embeddings = similarity_utils.extract_modality(\n",
    "        layer_modality=layer_modality,\n",
    "        modality=modality,\n",
    "        module_embedding=left_embedding,\n",
    "        module_name=layer_name,\n",
    "        image_token_id=IMAGE_TOKEN_IDS[model.config.architecture],\n",
    "        input_ids=left_input_ids,\n",
    "        module_embedding_same_shapes=left_same_shapes\n",
    "    )\n",
    "\n",
    "    right_modality_name, right_modality_embedding, right_n_embeddings = similarity_utils.extract_modality(\n",
    "        layer_modality=layer_modality,\n",
    "        modality=modality,\n",
    "        module_embedding=right_embedding,\n",
    "        module_name=layer_name,\n",
    "        image_token_id=IMAGE_TOKEN_IDS[model.config.architecture],\n",
    "        input_ids=right_input_ids,\n",
    "        module_embedding_same_shapes=right_same_shapes)\n",
    "\n",
    "    # Calculate mean embedding\n",
    "    left_mean_embeddings = db_utils.compute_mean_embeddings(\n",
    "        embeddings=left_modality_embedding,\n",
    "        n_embeddings=left_n_embeddings)\n",
    "\n",
    "    right_mean_embeddings = db_utils.compute_mean_embeddings(\n",
    "        embeddings=right_modality_embedding,\n",
    "        n_embeddings=right_n_embeddings)\n",
    "\n",
    "    similarities = db_utils.cosine_similarity_numpy(\n",
    "        left_mean_embeddings,\n",
    "        right_mean_embeddings,\n",
    "        elementwise=True)\n",
    "\n",
    "\n",
    "    print(layer_name, np.mean(similarities))\n",
    "    utils.write_file(similarities, save_path, overwrite=overwrite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd911ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622, 576, 1280)\n"
     ]
    }
   ],
   "source": [
    "print(left.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(right_layer_names, right_embeddings, _) = db_utils.get_all_embeddings(\n",
    "    db_path=right_db_path,\n",
    "    device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "818d8a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('visual.merger', array([[-2.6250000e+00, -1.9628906e-01,  7.3828125e-01, ...,\n",
      "         1.7031250e+00,  6.3750000e+00,  2.1972656e-02],\n",
      "       [-1.5703125e+00, -2.0000000e+00,  2.2187500e+00, ...,\n",
      "         8.9843750e-01,  4.7187500e+00,  4.3164062e-01],\n",
      "       [ 8.1640625e-01,  1.3515625e+00,  1.6171875e+00, ...,\n",
      "        -6.0156250e-01,  5.3515625e-01,  9.0625000e-01],\n",
      "       ...,\n",
      "       [ 6.9531250e-01,  3.6773682e-03, -2.9101562e-01, ...,\n",
      "         2.5000000e-01,  2.8710938e-01, -1.4941406e-01],\n",
      "       [-1.1669922e-01, -8.3984375e-01,  3.1640625e-01, ...,\n",
      "         6.3671875e-01,  7.2265625e-01, -2.3437500e-01],\n",
      "       [-3.5156250e+00, -6.6015625e-01, -4.0625000e-01, ...,\n",
      "         6.6406250e-01, -1.2265625e+00, -1.9453125e+00]], dtype=float32), None)\n"
     ]
    }
   ],
   "source": [
    "print(left_embeddings[2][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a718a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm-lens-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
