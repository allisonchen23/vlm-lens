vlm-competence-dev Documentation
================================

.. toctree::
   :maxdepth: 2
   :caption: Contents:

Overview
================
This repository provides utilities for extracting hidden states from
state-of-the-art vision-language models. By surfacing these intermediate
representations, you can perform a comprehensive analysis of the knowledge
encoded within each model.

Supported Models
================
We currently support extracting hidden states from the following vision-language models:

- BLIP-2  
- Clip  
- CogVLM  
- Glamm  
- InternLM-XComposer  
- InternVL  
- Janus  
- LLaVa  
- MiniCPM-V2  
- MiniCPM-o  
- Molmo  
- OMG-LLaVa  
- PaliGemma  
- Qwen  