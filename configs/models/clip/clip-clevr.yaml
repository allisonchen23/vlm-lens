architecture: clip
model_path: openai/clip-vit-base-patch32
model:
  - torch_dtype: auto
dataset:
  - dataset_path: compling/CLEVR_categories
  - dataset_split: color
output_db: output/clip-clevr.db
pooled_output: True
modules:
  - text_model.encoder.layers.5.layer_norm1
  - text_model.encoder.layers.11.layer_norm1
