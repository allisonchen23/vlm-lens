architecture: clip
model_path: openai/clip-vit-large-patch14
model:
  - torch_dtype: auto
output_db: output/clip-vit-large-patch14.db
input_dir: ./data/test-images/
prompt: "Describe the color in this image in one word."
modules:
  - visual_projection
  - text_projection
